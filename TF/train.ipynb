{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session started at Epoch =  0\n",
      "WARNING:tensorflow:<tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.GridLSTMCell object at 0x7fcaae099b80>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "[WARNING: rnn_cell_impl.py: 1326]: <tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.GridLSTMCell object at 0x7fcaae099b80>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:<tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.GridLSTMCell object at 0x7fcaae099d30>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "[WARNING: rnn_cell_impl.py: 1326]: <tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.GridLSTMCell object at 0x7fcaae099d30>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "time taken to generate proposals:0.05480074882507324: \n",
      "\n",
      "Time taken evaluate 10 predictions per each pedestrian + Social recommendation =  0.07411909103393555\n",
      "target_traj =  Tensor(\"Const:0\", shape=(11, 20, 2), dtype=float32)\n",
      "pred_path =  Tensor(\"Const_6:0\", shape=(10, 11, 20, 2), dtype=float32)\n",
      "\n",
      " time taken to recommend best adjacency proposal: 1.6835994720458984\n",
      "\n",
      "Short ADE 123.03734484585848\n",
      "Short ADE 83.3734692660245\n",
      "ADE =  24.249537\n",
      "FDE =  19.798403\n",
      "BackPropagation with SGD took:0.460618257522583\n",
      "\n",
      "Full pipeline time = 3.393810987472534\n",
      "============================\n",
      "Memory used: 0.96 GB\n",
      "============================\n",
      "[WARNING: train.py:  283]: 2.627763271331787 seconds to complete\n",
      "[WARNING: train.py:  284]: Batch = 0 of 313 Frame 20 Loss = 293.8988037109375, num_ped=11\n",
      "WARNING:tensorflow:<tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.GridLSTMCell object at 0x7fc973baa040>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "[WARNING: rnn_cell_impl.py: 1326]: <tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.GridLSTMCell object at 0x7fc973baa040>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:<tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.GridLSTMCell object at 0x7fc973baa910>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "[WARNING: rnn_cell_impl.py: 1326]: <tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.GridLSTMCell object at 0x7fc973baa910>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "time taken to generate proposals:0.06467556953430176: \n",
      "\n",
      "Time taken evaluate 10 predictions per each pedestrian + Social recommendation =  0.10033059120178223\n",
      "target_traj =  Tensor(\"Const_9:0\", shape=(8, 20, 2), dtype=float32)\n",
      "pred_path =  Tensor(\"Const_15:0\", shape=(10, 8, 20, 2), dtype=float32)\n",
      "\n",
      " time taken to recommend best adjacency proposal: 1.993974208831787\n",
      "\n",
      "Short ADE 84.19521271555047\n",
      "Short ADE 58.087584244577506\n",
      "ADE =  30.78728\n",
      "FDE =  23.319492\n",
      "BackPropagation with SGD took:0.5025177001953125\n",
      "\n",
      "Full pipeline time = 3.7942893505096436\n",
      "============================\n",
      "Memory used: 0.96 GB\n",
      "============================\n",
      "[WARNING: train.py:  283]: 2.8330729007720947 seconds to complete\n",
      "[WARNING: train.py:  284]: Batch = 1 of 313 Frame 40 Loss = 473.7743835449219, num_ped=8\n",
      "WARNING:tensorflow:<tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.GridLSTMCell object at 0x7fc9728ab880>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "[WARNING: rnn_cell_impl.py: 1326]: <tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.GridLSTMCell object at 0x7fc9728ab880>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:<tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.GridLSTMCell object at 0x7fc9728aba30>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "[WARNING: rnn_cell_impl.py: 1326]: <tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.GridLSTMCell object at 0x7fc9728aba30>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1076: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n",
      "/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1076: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to generate proposals:0.12494969367980957: \n",
      "\n",
      "Time taken evaluate 10 predictions per each pedestrian + Social recommendation =  0.12246465682983398\n",
      "target_traj =  Tensor(\"Const_18:0\", shape=(11, 20, 2), dtype=float32)\n",
      "pred_path =  Tensor(\"Const_24:0\", shape=(10, 11, 20, 2), dtype=float32)\n",
      "\n",
      " time taken to recommend best adjacency proposal: 2.4951624870300293\n",
      "\n",
      "Short ADE 62.21513144175211\n",
      "Short ADE 44.04821802775065\n",
      "ADE =  24.24954\n",
      "FDE =  19.798403\n",
      "BackPropagation with SGD took:0.5479533672332764\n",
      "\n",
      "Full pipeline time = 4.329988718032837\n",
      "============================\n",
      "Memory used: 1.00 GB\n",
      "============================\n",
      "[WARNING: train.py:  283]: 3.075162649154663 seconds to complete\n",
      "[WARNING: train.py:  284]: Batch = 2 of 313 Frame 60 Loss = 293.8988952636719, num_ped=11\n",
      "WARNING:tensorflow:<tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.GridLSTMCell object at 0x7fc9725b3a30>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "[WARNING: rnn_cell_impl.py: 1326]: <tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.GridLSTMCell object at 0x7fc9725b3a30>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:<tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.GridLSTMCell object at 0x7fc9725b3be0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "[WARNING: rnn_cell_impl.py: 1326]: <tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.GridLSTMCell object at 0x7fc9725b3be0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "time taken to generate proposals:0.1287388801574707: \n",
      "\n",
      "Time taken evaluate 10 predictions per each pedestrian + Social recommendation =  0.14177918434143066\n",
      "target_traj =  Tensor(\"Const_27:0\", shape=(15, 20, 2), dtype=float32)\n",
      "pred_path =  Tensor(\"Const_33:0\", shape=(10, 15, 20, 2), dtype=float32)\n",
      "\n",
      " time taken to recommend best adjacency proposal: 3.308711290359497\n",
      "\n",
      "Short ADE 49.41676055060493\n",
      "Short ADE 34.893905809190535\n",
      "ADE =  23.820019\n",
      "FDE =  16.585283\n",
      "BackPropagation with SGD took:0.6118888854980469\n",
      "\n",
      "Full pipeline time = 5.222188711166382\n",
      "============================\n",
      "Memory used: 1.05 GB\n",
      "============================\n",
      "[WARNING: train.py:  283]: 3.6232717037200928 seconds to complete\n",
      "[WARNING: train.py:  284]: Batch = 3 of 313 Frame 80 Loss = 283.57757568359375, num_ped=15\n",
      "WARNING:tensorflow:<tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.GridLSTMCell object at 0x7fc97228bb50>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "[WARNING: rnn_cell_impl.py: 1326]: <tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.GridLSTMCell object at 0x7fc97228bb50>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:<tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.GridLSTMCell object at 0x7fc97228bca0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "[WARNING: rnn_cell_impl.py: 1326]: <tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.GridLSTMCell object at 0x7fc97228bca0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "time taken to generate proposals:0.1502971649169922: \n",
      "\n",
      "Time taken evaluate 10 predictions per each pedestrian + Social recommendation =  0.15505695343017578\n",
      "target_traj =  Tensor(\"Const_36:0\", shape=(10, 20, 2), dtype=float32)\n",
      "pred_path =  Tensor(\"Const_42:0\", shape=(10, 10, 20, 2), dtype=float32)\n",
      "\n",
      " time taken to recommend best adjacency proposal: 3.1954503059387207\n",
      "\n",
      "Short ADE 45.299456336281516\n",
      "Short ADE 32.844974448464136\n",
      "ADE =  26.771587\n",
      "FDE =  23.624784\n",
      "BackPropagation with SGD took:0.6882355213165283\n",
      "\n",
      "Full pipeline time = 5.246447324752808\n",
      "============================\n",
      "Memory used: 1.11 GB\n",
      "============================\n",
      "[WARNING: train.py:  283]: 3.5594840049743652 seconds to complete\n",
      "[WARNING: train.py:  284]: Batch = 4 of 313 Frame 100 Loss = 358.2251281738281, num_ped=10\n",
      "WARNING:tensorflow:<tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.GridLSTMCell object at 0x7fc971f97070>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "[WARNING: rnn_cell_impl.py: 1326]: <tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.GridLSTMCell object at 0x7fc971f97070>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:<tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.GridLSTMCell object at 0x7fc97289dd00>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "[WARNING: rnn_cell_impl.py: 1326]: <tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.GridLSTMCell object at 0x7fc97289dd00>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "time taken to generate proposals:0.18099093437194824: \n",
      "\n",
      "Time taken evaluate 10 predictions per each pedestrian + Social recommendation =  0.18056726455688477\n",
      "target_traj =  Tensor(\"Const_45:0\", shape=(13, 20, 2), dtype=float32)\n",
      "pred_path =  Tensor(\"Const_51:0\", shape=(10, 13, 20, 2), dtype=float32)\n",
      "\n",
      " time taken to recommend best adjacency proposal: 3.7596583366394043\n",
      "\n",
      "Short ADE 42.16510657703175\n",
      "Short ADE 30.978225147022922\n",
      "ADE =  28.904396\n",
      "FDE =  23.080437\n",
      "BackPropagation with SGD took:0.7298898696899414\n",
      "\n",
      "Full pipeline time = 5.865017414093018\n",
      "============================\n",
      "Memory used: 1.18 GB\n",
      "============================\n",
      "[WARNING: train.py:  283]: 3.883016586303711 seconds to complete\n",
      "[WARNING: train.py:  284]: Batch = 5 of 313 Frame 120 Loss = 417.58758544921875, num_ped=13\n",
      "WARNING:tensorflow:<tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.GridLSTMCell object at 0x7fc971c9c430>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "[WARNING: rnn_cell_impl.py: 1326]: <tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.GridLSTMCell object at 0x7fc971c9c430>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:<tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.GridLSTMCell object at 0x7fc971e7f040>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "[WARNING: rnn_cell_impl.py: 1326]: <tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.GridLSTMCell object at 0x7fc971e7f040>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1076: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to generate proposals:0.23397231101989746: \n",
      "\n",
      "Time taken evaluate 10 predictions per each pedestrian + Social recommendation =  0.2047271728515625\n",
      "target_traj =  Tensor(\"Const_54:0\", shape=(13, 20, 2), dtype=float32)\n",
      "pred_path =  Tensor(\"Const_60:0\", shape=(10, 13, 20, 2), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-144:\n",
      "Process ForkPoolWorker-138:\n",
      "Process ForkPoolWorker-139:\n",
      "Process ForkPoolWorker-141:\n",
      "Process ForkPoolWorker-146:\n",
      "Process ForkPoolWorker-137:\n",
      "Process ForkPoolWorker-140:\n",
      "Process ForkPoolWorker-143:\n",
      "Process ForkPoolWorker-147:\n",
      "Process ForkPoolWorker-148:\n",
      "Process ForkPoolWorker-142:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-145:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " time taken to recommend best adjacency proposal: 4.225939035415649\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/queues.py\", line 356, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/sisi/anaconda3/envs/pythonProject/lib/python3.8/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_59525/1359324874.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0m__name__\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'__main__'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m     \u001B[0mmain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_59525/1359324874.py\u001B[0m in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0;31m# sys.argv = ['-f']\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0margs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mparse\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mArgsParser\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m     \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparser\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparse_args\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m     \u001B[0;32mreturn\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Sirius_challenge/traj_rcmndr-master/TF/train.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(args)\u001B[0m\n\u001B[1;32m    312\u001B[0m     \u001B[0;31m# tf.compat.v1.enable_eager_execution()\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    313\u001B[0m     \u001B[0mSTRGGRNN_model_train\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 314\u001B[0;31m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/Documents/Sirius_challenge/traj_rcmndr-master/TF/train.py\u001B[0m in \u001B[0;36mSTRGGRNN_model_train\u001B[0;34m(out_graph, args)\u001B[0m\n\u001B[1;32m    247\u001B[0m                     \u001B[0;31m# ade_min = tf.reduce_min(ade_losses)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    248\u001B[0m                     \u001B[0mbst_adj_prop\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnri_obj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madj_mat_vec\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mmin_idx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meval\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 249\u001B[0;31m                     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Short ADE'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtotal_ade\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0mnum_nodes\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    250\u001B[0m                     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Short ADE'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtotal_fde\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0mnum_nodes\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    251\u001B[0m                     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'ADE = '\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0made_bst\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meval\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001B[0m in \u001B[0;36meval\u001B[0;34m(self, feed_dict, session)\u001B[0m\n\u001B[1;32m    911\u001B[0m       \u001B[0mA\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[0marray\u001B[0m \u001B[0mcorresponding\u001B[0m \u001B[0mto\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mvalue\u001B[0m \u001B[0mof\u001B[0m \u001B[0mthis\u001B[0m \u001B[0mtensor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    912\u001B[0m     \"\"\"\n\u001B[0;32m--> 913\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_eval_using_default_session\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfeed_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgraph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msession\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    914\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    915\u001B[0m   \u001B[0;34m@\u001B[0m\u001B[0mdeprecation\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdeprecated\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"Use ref() instead.\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001B[0m in \u001B[0;36m_eval_using_default_session\u001B[0;34m(tensors, feed_dict, graph, session)\u001B[0m\n\u001B[1;32m   5510\u001B[0m                        \u001B[0;34m\"the tensor's graph is different from the session's \"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5511\u001B[0m                        \"graph.\")\n\u001B[0;32m-> 5512\u001B[0;31m   \u001B[0;32mreturn\u001B[0m \u001B[0msession\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfeed_dict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   5513\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5514\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(self, fetches, feed_dict, options, run_metadata)\u001B[0m\n\u001B[1;32m    955\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    956\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 957\u001B[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001B[0m\u001B[1;32m    958\u001B[0m                          run_metadata_ptr)\n\u001B[1;32m    959\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0mrun_metadata\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001B[0m in \u001B[0;36m_run\u001B[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001B[0m\n\u001B[1;32m   1178\u001B[0m     \u001B[0;31m# or if the call is a partial run that specifies feeds.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1179\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mfinal_fetches\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mfinal_targets\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mhandle\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mfeed_dict_tensor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1180\u001B[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001B[0m\u001B[1;32m   1181\u001B[0m                              feed_dict_tensor, options, run_metadata)\n\u001B[1;32m   1182\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001B[0m in \u001B[0;36m_do_run\u001B[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001B[0m\n\u001B[1;32m   1356\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1357\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mhandle\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1358\u001B[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001B[0m\u001B[1;32m   1359\u001B[0m                            run_metadata)\n\u001B[1;32m   1360\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001B[0m in \u001B[0;36m_do_call\u001B[0;34m(self, fn, *args)\u001B[0m\n\u001B[1;32m   1363\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_do_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1364\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1365\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1366\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0merrors\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mOpError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1367\u001B[0m       \u001B[0mmessage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcompat\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mas_text\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmessage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001B[0m in \u001B[0;36m_run_fn\u001B[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001B[0m\n\u001B[1;32m   1347\u001B[0m       \u001B[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1348\u001B[0m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_extend_graph\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1349\u001B[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001B[0m\u001B[1;32m   1350\u001B[0m                                       target_list, run_metadata)\n\u001B[1;32m   1351\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001B[0m in \u001B[0;36m_call_tf_sessionrun\u001B[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001B[0m\n\u001B[1;32m   1439\u001B[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001B[1;32m   1440\u001B[0m                           run_metadata):\n\u001B[0;32m-> 1441\u001B[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001B[0m\u001B[1;32m   1442\u001B[0m                                             \u001B[0mfetch_list\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarget_list\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1443\u001B[0m                                             run_metadata)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from train import train\n",
    "import argParser as parse\n",
    "import sys\n",
    "\n",
    "def main():\n",
    "    # sys.argv = ['-f']\n",
    "    args = parse.ArgsParser()\n",
    "    train(args.parser.parse_args())\n",
    "    return\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}